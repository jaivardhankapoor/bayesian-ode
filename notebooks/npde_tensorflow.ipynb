{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'npde'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-819012407552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# %matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnpde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmoothODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeInvariantBrownian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'npde'"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from scipy.stats import norm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "float_type = tf.float32\n",
    "\n",
    "modelPath = './npde.ckpt/npode'\n",
    "tbPath = './npde.summ'\n",
    "# %matplotlib inline\n",
    "\n",
    "from npde.utils import *\n",
    "from npde.plotting import *\n",
    "from npde.diffusions import SmoothODE, TimeInvariantBrownian\n",
    "from npde.npde import NPODE, NPSDE\n",
    "from npde.kernels import RBF, OperatorKernel\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# van der pol data\n",
    "Ny = [30,31,32,33]\n",
    "Nt = 4\n",
    "tend = 7\n",
    "nstd = 0.1\n",
    "x0 = np.asarray([[2.0,-2.0],[2.0,-2.0]],dtype=np.float32)\n",
    "x0p,tp,Yp,X,ftrue,gtrue = gen_data('vdp',x0=x0,Ny=Ny,Nt=Nt,tend=tend,nstd=nstd)\n",
    "D = 2\n",
    "Yhighp = None\n",
    "%matplotlib inline\n",
    "plot_data(tp,Yp,ftrue,gtrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# npde initialization\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# params\n",
    "ind_grid = True\n",
    "W  = 5   # grid size\n",
    "M  = 100 # total number of inducing points if there is no grid\n",
    "Mt = 8   # number of time slices if spatio-temporal kronecker form \n",
    "sf0    = 1.0\n",
    "ell0   = 1.25*np.ones(D) # 1.25\n",
    "ellt0  = 1.0\n",
    "sn0    = 0.1*np.ones(D)\n",
    "ktype  = \"id\"\n",
    "eta = 3e-3\n",
    "whiten = True\n",
    "\n",
    "# initialization\n",
    "def init_U0(sess=None,Y=None,t=None,t0=None,kern=None,Z0=None,whiten=None):\n",
    "    Ug = (Y[1:,:] - Y[:-1,:]) / np.reshape(t[1:]-t[:-1],(-1,1))\n",
    "    if ktype == 'tid':\n",
    "        t = np.reshape(t,[-1,1])\n",
    "        Y = np.hstack((Y,t))\n",
    "    tmp = NPODE(_,Z0=Y[:-1,:],U0=Ug,sn0=0,kern=kern,jitter=0.2,whiten=False,\n",
    "                summ=False,fix_Z=True,fix_U=True,fix_Zt=True,fix_sn=True)\n",
    "    U0 = tmp.f(X=Z0)\n",
    "#     U0 = np.zeros_like(Z0,dtype=np.float32)\n",
    "#     for i in range(U0.shape[0]):\n",
    "#         U0[i,:] = vdp(Z0[i,:],t[i])\n",
    "    if whiten:\n",
    "        Lz = tf.cholesky( kern.K(Z0)+tf.eye(Mx)*1e-3 ) \n",
    "        U0 = tf.matrix_triangular_solve(Lz, U0, lower=True)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    U0 = sess.run(U0)\n",
    "    return U0\n",
    "    \n",
    "# create ind. points along space\n",
    "if D==1:\n",
    "    W = 10\n",
    "    Mx = W\n",
    "    Z0 = np.linspace(-4, 4, W).reshape((-1,1))\n",
    "elif D==2:\n",
    "    xv = np.linspace(np.min([np.min(Y[:,0]) for Y in Yp]), np.max([np.max(Y[:,0]) for Y in Yp]), W)\n",
    "    yv = np.linspace(np.min([np.min(Y[:,1]) for Y in Yp]), np.max([np.max(Y[:,1]) for Y in Yp]), W)\n",
    "#     xv = np.linspace(-3, 3, W)\n",
    "#     yv = np.linspace(-3, 3, W)\n",
    "    Mx = W*W\n",
    "    xv,yv = np.meshgrid(xv,yv)\n",
    "    Z0 = np.array([xv.T.flatten(),yv.T.flatten()]).T\n",
    "else:\n",
    "    if ind_grid:\n",
    "        xv = np.linspace(np.min([np.min(Y[:,0]) for Y in Yp]), np.max([np.max(Y[:,0]) for Y in Yp]), W)\n",
    "        yv = np.linspace(np.min([np.min(Y[:,1]) for Y in Yp]), np.max([np.max(Y[:,1]) for Y in Yp]), W)\n",
    "        zv = np.linspace(np.min([np.min(Y[:,2]) for Y in Yp]), np.max([np.max(Y[:,2]) for Y in Yp]), W)\n",
    "        Mx = W*W*W\n",
    "        xv,yv,zv = np.meshgrid(xv,yv,zv)\n",
    "        Z0 = np.array([xv.T.flatten(),yv.T.flatten(),zv.T.flatten()]).T\n",
    "    else:\n",
    "        Mx = M\n",
    "        if ktype == \"id\":\n",
    "            data_ = np.empty((0,D))\n",
    "            for i in range(len(Yp)):\n",
    "                data_ = np.concatenate((data_,Yp[i]))\n",
    "            Z0 = kmeans2(data_, M, minit='points')[0]\n",
    "            Z0 += ss.norm.rvs(size=Z0.shape)*0.0\n",
    "        elif ktype == \"tid\":\n",
    "            ell0 = np.hstack((ell0,ellt0))\n",
    "            data_ = np.empty((0,D+1))\n",
    "            Ys = []\n",
    "            for i in range(len(Yp)):\n",
    "                Ys.append(np.hstack((Yp[i],np.reshape(tp[i],[-1,1]))))\n",
    "                data_ = np.concatenate((data_,Ys[i]))\n",
    "            Z0 = kmeans2(data_, M, minit='points')[0]\n",
    "#             Z0 += ss.norm.rvs(size=Z0.shape)*0.0\n",
    "            \n",
    "# for i in range(20):\n",
    "#     dists = np.sum((Z0[1:,:-1]-Z0[:-1,:-1])**2,1)\n",
    "#     amax = np.argmax(dists)\n",
    "#     amin = np.argmin(dists)\n",
    "#     Z0[amin,:] = (Z0[amax,:]+Z0[amax+1,:])/2\n",
    "#     Z0 = Z0[np.argsort(Z0[:,-1]),:]\n",
    "# plt.plot(dists)\n",
    "    \n",
    "\n",
    "# create ind. points along time\n",
    "mxidx = 0\n",
    "mxlen = -1\n",
    "for i in range(len(tp)):\n",
    "    if mxlen < len(tp[i]):\n",
    "        mxlen = len(tp[i])\n",
    "        mxidx = i\n",
    "t0 = np.sort(kmeans2(tp[mxidx], Mt, minit='points')[0])\n",
    "\n",
    "tmp_kern = OperatorKernel(sf0,ell0,ktype=\"id\",fix_ell=True,fix_sf=True,fix_ellt=True)\n",
    "if ktype == \"id\" or ktype == \"tid\":\n",
    "    U0 = np.zeros((Mx,D),dtype=np.float32)\n",
    "    for i in range(len(Yp)):\n",
    "        U0 += init_U0(sess,Yp[i],tp[i],t0,tmp_kern,Z0,whiten)\n",
    "    U0 /= len(Yp)\n",
    "elif ktype == \"kr\":\n",
    "    U0 = np.zeros((Mx*Mt,D))\n",
    "    for t_ in range(Mt):\n",
    "        U0t = np.zeros(Z0.shape,dtype=np.float32)\n",
    "        for i in range(len(Yp)):\n",
    "            U0t += init_U0(sess,Yp[i][t_*Mx:(t_+1)*Mx,:],\n",
    "                                tp[i][t_*Mx:(t_+1)*Mx],t0,tmp_kern,Z0,whiten)\n",
    "        U0[np.arange(t_*Mx,(t_+1)*Mx),:] = U0t / len(Yp)\n",
    "\n",
    "lensp = [len(ti) for ti in tp]\n",
    "dataset = DataSet(x0p,tp,Yp,lensp,Yhighp)\n",
    "x0   = tf.placeholder(tf.float32,name='x0_placeholder')\n",
    "t    = tf.placeholder(tf.float32,name='t_placeholder')\n",
    "Y    = tf.placeholder(tf.float32,name='Y_placeholder')\n",
    "lens = tf.placeholder(tf.int32,name='lens_placeholder')\n",
    "Yhigh = tf.placeholder(tf.float32,name='Yhigh_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# npODE\n",
    "\n",
    "# U0 += np.random.normal(0,1,(Mx,D))\n",
    "# U0 = samples[0][2841]\n",
    "\n",
    "kern = OperatorKernel(sf0=sf0,\n",
    "                        ell0=ell0,\n",
    "                        ktype=\"id\",\n",
    "                        learning_rate=eta,\n",
    "                        summ=False,\n",
    "                        fix_ell=True,\n",
    "                        fix_sf=True,\n",
    "                        fix_ellt=True)\n",
    "\n",
    "npde = NPODE(dataset=dataset,\n",
    "            Z0=Z0,\n",
    "            U0=U0,\n",
    "            sn0=sn0,\n",
    "            kern=kern,\n",
    "            learning_rate=eta,\n",
    "            summ=False,\n",
    "            whiten=whiten,\n",
    "            fix_Z=True,\n",
    "            fix_U=False,\n",
    "            fix_sn=True,\n",
    "            fix_Zt=True)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "with tf.name_scope(\"cost\"):\n",
    "    Xs = npde.forward(t=t,x0=x0,lens=lens)\n",
    "    def ll(x):\n",
    "        Ny = x[2]\n",
    "        X = tf.gather(x[0],tf.range(0,Ny),axis=0)\n",
    "        Y = tf.gather(x[1],tf.range(0,Ny),axis=0)\n",
    "        mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=Y,covariance_matrix=tf.diag(npde.sn))\n",
    "        ll = tf.reduce_sum(mvn.log_prob(X))\n",
    "        return ll,ll,tf.constant([1])\n",
    "    ll,_,_ = tf.map_fn(ll,(Xs,Y,lens),dtype=(tf.float32,tf.float32,tf.int32))\n",
    "    ll = tf.reduce_sum(ll)\n",
    "    ode_prior = npde.build_prior()\n",
    "    cost = -(ll + ode_prior)\n",
    "\n",
    "x0_,t_,Y_,lens_,Yhigh_ = dataset.next_batch(0)\n",
    "dict_ = {x0:x0_, t:t_, Y:Y_, Yhigh:Yhigh_, lens:lens_}\n",
    "\n",
    "print(cost.eval(feed_dict=dict_))\n",
    "plot_model(npde,ftrue=ftrue)\n",
    "    \n",
    "def npde_post(sn,U,N=0):\n",
    "    npde.sn = sn\n",
    "    npde.U = U\n",
    "    x0 = npde.dataset.x0t\n",
    "    Y = npde.dataset.Yt\n",
    "    t = npde.dataset.tt\n",
    "    lens = npde.dataset.lenst\n",
    "#     return -cost\n",
    "    Xs = npde.forward(t=t,x0=x0,lens=lens)\n",
    "    def ll(x):\n",
    "        Ny = x[2]\n",
    "        X = tf.gather(x[0],tf.range(0,Ny),axis=0)\n",
    "        Y = tf.gather(x[1],tf.range(0,Ny),axis=0)\n",
    "        mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=Y,covariance_matrix=tf.diag(npde.sn))\n",
    "        ll = tf.reduce_sum(mvn.log_prob(X))\n",
    "        return ll,ll,tf.constant([1])\n",
    "    ll,_,_ = tf.map_fn(ll,(Xs,Y,lens),dtype=(tf.float32,tf.float32,tf.int32))\n",
    "    ll = tf.reduce_sum(ll)\n",
    "    ode_prior = npde.build_prior()\n",
    "    return ll + ode_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# npSDE\n",
    "kern = OperatorKernel(sf0=sf0,\n",
    "          ell0=ell0,\n",
    "          ktype=\"id\",\n",
    "          learning_rate=eta,\n",
    "          summ=False,\n",
    "          fix_ell=True,\n",
    "          fix_sf=True,\n",
    "          fix_ellt=True)\n",
    "\n",
    "# diffus = SmoothODE(sf0sig=1.0, ell0sig=[1e5],\n",
    "#            sf0gp=0.1, ell0gp=0.1,\n",
    "#            U0=np.ones([Z0.shape[0],1])*0.00, Z0=Z0,\n",
    "#            D=D,\n",
    "#            summ=False,\n",
    "#            whiten=True,\n",
    "#            jitter=1e-4,\n",
    "#            fix_sfsig=True,fix_ellsig=True,\n",
    "#            fix_sfgp=False,fix_ellgp=False,\n",
    "#            fix_U=True,fix_Z=True)\n",
    "\n",
    "diffus = TimeInvariantBrownian(sf0=1.0,\n",
    "           ell0 = 1e5*np.ones(1,dtype=np.float32),\n",
    "           U0 = np.ones([Z0.shape[0],1])*0.01,\n",
    "           Z0 = Z0,\n",
    "           whiten=True,\n",
    "           fix_sf=True,\n",
    "           fix_ell=True,\n",
    "           fix_Z=True,\n",
    "           fix_U=False)\n",
    "    \n",
    "npde = NPSDE(dataset=dataset,\n",
    "              Z0=Z0,\n",
    "              U0=U0,\n",
    "              sn0=sn0,\n",
    "              kern=kern,\n",
    "              jitter=1e-5,\n",
    "              diffus=diffus,\n",
    "              learning_rate=eta,\n",
    "              summ=False,\n",
    "              whiten=whiten,\n",
    "              fix_Z=True,\n",
    "              fix_U=False,\n",
    "              fix_sn=False,\n",
    "              fix_Zt=True)\n",
    "\n",
    "with tf.name_scope(\"npde-cost\"):\n",
    "    Xs = npde.forward(Nw=50,t=t,x0=x0,lens=lens)\n",
    "    def ll(x):\n",
    "        Ny = x[2]\n",
    "        X = tf.gather(x[0],tf.range(0,Ny),axis=1)\n",
    "        Y = tf.gather(x[1],tf.range(0,Ny),axis=0)\n",
    "        mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=Y,covariance_matrix=tf.diag(npde.sn))\n",
    "        lls = tf.map_fn(lambda x: mvn.log_prob(x), X, dtype=tf.float32) # Nw x Ndata\n",
    "        # ll = tf.reduce_sum(tf.log(tf.reduce_mean(tf.exp(lls),axis=0)))\n",
    "        ll = tf.reduce_sum(logmeanexp(lls,axis=0))\n",
    "        return ll,ll,tf.constant([1])\n",
    "    ll,_,_ = tf.map_fn(ll,(Xs,Y,lens),dtype=(tf.float32,tf.float32,tf.int32))\n",
    "    ll = tf.reduce_sum(ll)\n",
    "    prior = npde.build_prior()\n",
    "    cost = -(ll + prior)\n",
    "    \n",
    "def npde_post(sn,U,sf,ell,N=0):\n",
    "    npde.sn = sn\n",
    "    npde.U = U\n",
    "    npde.diffus.kern_time.sf  = sf\n",
    "    npde.diffus.kern_time.ell = ell\n",
    "    x0 = npde.dataset.x0t\n",
    "    Y = npde.dataset.Yt\n",
    "    t = npde.dataset.tt\n",
    "    lens = npde.dataset.lenst\n",
    "    Xs = npde.forward(Nw=50,t=t,x0=x0,lens=lens)\n",
    "    def ll(x):\n",
    "        Ny = x[2]\n",
    "        X = tf.gather(x[0],tf.range(0,Ny),axis=1)\n",
    "        Y = tf.gather(x[1],tf.range(0,Ny),axis=0)\n",
    "        mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=Y,covariance_matrix=tf.diag(npde.sn))\n",
    "        lls = tf.map_fn(lambda x: mvn.log_prob(x), X, dtype=tf.float32) # Nw x Ndata\n",
    "        ll = tf.reduce_sum(tf.log(tf.reduce_mean(tf.exp(lls),axis=0)))\n",
    "        return ll,ll,tf.constant([1])\n",
    "    ll,_,_ = tf.map_fn(ll,(Xs,Y,lens),dtype=(tf.float32,tf.float32,tf.int32))\n",
    "    ll = tf.reduce_sum(ll)\n",
    "    prior = npde.build_prior()\n",
    "    return ll + prior\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "x0_,t_,Y_,lens_,Yhigh_ = dataset.next_batch(0)\n",
    "dict_ = {x0:x0_, t:t_, Y:Y_, lens:lens_}\n",
    "print(cost.eval(feed_dict=dict_))\n",
    "\n",
    "Xp = plot_model(npde,Nw=50,ftrue=ftrue)\n",
    "\n",
    "\n",
    "# Xs = npde.forward(Nw=5)\n",
    "# Xs = Xs[0].eval()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# for j in range(3):\n",
    "#     plt.plot(Xs[j,:])\n",
    "# plt.title('Random draws, cost={:f}'.format(cost.eval()));\n",
    "\n",
    "# Xs = [op.eval() for op in Xs]\n",
    "# cost.eval()\n",
    "# plt.figure(figsize=(10,10))\n",
    "# for j in range(len(Xs)):\n",
    "#     print(Xs[j].shape)\n",
    "#     for i in range(Xs[j].shape[0]):\n",
    "#         plt.plot(Xs[j][i,:,0],Xs[j][i,:,1],'.-',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# prepare optimization\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "expdec = tf.train.exponential_decay(1e-3,global_step,20,0.99,staircase=True)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(expdec).minimize(cost,global_step)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(global_step.initializer)\n",
    "\n",
    "all_var_list = tf.trainable_variables()\n",
    "for i in all_var_list:\n",
    "    print(i)\n",
    "    \n",
    "def variable_summaries():\n",
    "    tf.summary.scalar('cost',cost)\n",
    "    tf.summary.scalar('sf-f',npde.kern.sf)\n",
    "    if 'gplvm' in globals():\n",
    "        tf.summary.scalar('gplvm-beta',gplvm.beta)\n",
    "        tf.summary.scalar('gplvm-sf',gplvm.kern.sf)\n",
    "        for i in range(D):\n",
    "            tf.summary.scalar('gplvm-ell-{:d}'.format(i+1),gplvm.kern.ell[i])\n",
    "    for i in range(D):\n",
    "        tf.summary.scalar('ell-f-{:d}'.format(i+1),npde.kern.ell[i])\n",
    "        tf.summary.scalar('sn-{:d}'.format(i+1),npde.sn[i])\n",
    "    if npde.name == 'npsde' and npde.diffus.name == 'smoothode':\n",
    "        tf.summary.scalar('sf-g',npde.diffus.kern_time.sf)\n",
    "        tf.summary.scalar('ell-g',npde.diffus.kern_time.ell)\n",
    "        \n",
    "variable_summaries()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(tbPath,graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run optimization\n",
    "\n",
    "# saver.restore(sess,modelPath)\n",
    "# tensorboard --logdir npde.summ\n",
    "# python -m tensorboard.main --logdir npde.summ\n",
    "# http://localhost:6006/\n",
    "\n",
    "print('{:>16s}'.format(\"iteration\")+'{:>16s}'.format(\"objective\"))\n",
    "num_iter = 100\n",
    "\n",
    "# from gpflow import transforms\n",
    "# transform=transforms.Log1pe()\n",
    "# sess.run(all_var_list[4].assign(transform.backward(np.asarray([0.01,0.01]))))\n",
    "# npde.sn = tf.constant(0.01*np.ones(3), dtype=np.float32)\n",
    "\n",
    "t1 = time.time()\n",
    "times = []\n",
    "costs = []\n",
    "cost_best = 1e4\n",
    "for i in range(num_iter):\n",
    "    x0_,t_,Y_,lens_,Yhigh_ = dataset.next_batch(0)\n",
    "    dict_ = {x0:x0_, t:t_, Y:Y_, Yhigh:Yhigh_, lens:lens_}\n",
    "\n",
    "    # batch = batch_gen.next()\n",
    "    if i%5==0 or i==0 or i==num_iter-1:\n",
    "#         saver.save(sess,modelPath)\n",
    "#         npde.save('gsde50-simulated.pkl')\n",
    "        cost_,_ = sess.run([cost,optimizer],feed_dict=dict_)\n",
    "        merged = tf.summary.merge_all()\n",
    "        summary = sess.run(merged,feed_dict=dict_)\n",
    "        summary_writer.add_summary(summary,i)\n",
    "        summary_writer.flush()\n",
    "    else:\n",
    "        cost_,_ = sess.run([cost,optimizer],feed_dict=dict_)\n",
    "    print('{:>16d}'.format(i)+'{:>16.3f}'.format(cost_))\n",
    "    costs.append(cost_)\n",
    "    if cost_<cost_best:\n",
    "        npde.save('golf_st_ode.pkl')\n",
    "        cost_best = cost_\n",
    "    times.append(time.time()-t1)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "Xs = plot_model(npde,Nw=50,lp=cost_,ftrue=ftrue)\n",
    "\n",
    "# save the data\n",
    "# make sure that projection is consistent with how the data is read (mean centering, scaling, num. dims 50 or 62, etc)\n",
    "# Xrec = np.matmul(np.matmul(Xs[0],np.diag(np.sqrt(v[:D]))),np.transpose(u[:,:D])) + means\n",
    "# import scipy.io\n",
    "# scipy.io.savemat('Xrec.mat',{'Y':Xrec,'initY':initY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot model\n",
    "%matplotlib inline\n",
    "Xs = plot_model(npde,Nw=10,lp=cost_,ftrue=ftrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Langevin and HAMCMC\n",
    "post = -cost\n",
    "x0_,t_,Y_,lens_,Yhigh_ = dataset.next_batch(0)\n",
    "dict_ = {x0:x0_, t:t_, Y:Y_, Yhigh:Yhigh_, lens:lens_}\n",
    "thetas = tf.trainable_variables()\n",
    "grads = tf.gradients(post,thetas)\n",
    "th_D = sum([tf.size(grad).eval() for grad in grads])\n",
    "\n",
    "M = 2 # lbfgs memory\n",
    "lamb = 0.1 # lbfgs constant\n",
    "Slbfgs = np.zeros((M,th_D)) # stores parameters\n",
    "Ylbfgs = np.zeros((M,th_D)) # stores grads\n",
    "\n",
    "eta = 5e-5\n",
    "Nsamp = 50\n",
    "\n",
    "def get_th():\n",
    "    return [t.eval() for t in thetas]\n",
    "\n",
    "def set_th(new_th):\n",
    "    for i,theta in enumerate(thetas):\n",
    "        tf.assign(theta,new_th[i]).eval()\n",
    "        \n",
    "def get_post(feed_dict=dict_):\n",
    "    return post.eval(feed_dict=feed_dict)\n",
    "\n",
    "def get_new_post(new_th, feed_dict=dict_):\n",
    "    old_th = get_th()\n",
    "    set_th(new_th)\n",
    "    post_ = get_post(feed_dict)\n",
    "    set_th(old_th)\n",
    "    return post_\n",
    "\n",
    "def get_grad_vec(feed_dict=dict_):\n",
    "    grad_vec = [sess.run(grad,feed_dict=dict_) for grad in grads]\n",
    "    grad_vec = [grad.flatten() for grad in grad_vec]\n",
    "    return np.array(grad_vec).flatten()\n",
    "\n",
    "def get_th_vec():\n",
    "    th_vec = [sess.run(th) for th in thetas]\n",
    "    th_vec = [th.flatten() for th in th_vec]\n",
    "    return np.array(th_vec).flatten()\n",
    "\n",
    "def th_vec_to_arr(th_vec):\n",
    "    th_arr = []\n",
    "    iter_ = 0\n",
    "    for i,theta in enumerate(thetas):\n",
    "        th_shape = tf.shape(theta).eval()\n",
    "        th_size = tf.size(theta).eval()\n",
    "        th = th_vec[iter_:iter_+th_size]\n",
    "        th_arr.append(np.reshape(th,th_shape))\n",
    "        iter_ += th_size\n",
    "    return th_arr\n",
    "\n",
    "def set_th_vec(th_vec):\n",
    "    iter_ = 0\n",
    "    for i,theta in enumerate(thetas):\n",
    "        th_size = tf.size(thetas[0]).eval()\n",
    "        th = th_vec[iter_:iter_+th_size]\n",
    "        tf.assign(theta,th).eval()\n",
    "        iter_ += th_size\n",
    "    \n",
    "def init_sample_batches(Nsamp=Nsamp):\n",
    "    thetas = tf.trainable_variables()\n",
    "    for th in thetas:\n",
    "        print(th)\n",
    "    print()\n",
    "    posts = np.zeros((Nsamp))\n",
    "    samps = []\n",
    "    for theta in thetas:\n",
    "        th_shape = tf.shape(thetas[0]).eval()\n",
    "        samps.append(np.zeros((Nsamp,th_shape[0],th_shape[1])))\n",
    "    return posts,samps\n",
    "\n",
    "def save_samples(epoch,post,thetas):\n",
    "    posts[epoch] = post\n",
    "    for i,theta in enumerate(thetas):\n",
    "        samples[i][epoch] = theta\n",
    "    \n",
    "def lmc_new_th(eta=eta,feed_dict=dict_):\n",
    "    new_th = []\n",
    "    for i,theta in enumerate(thetas):\n",
    "        new_th_i = theta + eta*grads[i] + tf.sqrt(2*eta)*tf.random_normal(tf.shape(theta))\n",
    "        new_th_i = sess.run(new_th_i,dict_)\n",
    "        new_th.append(new_th_i)\n",
    "    return new_th\n",
    "\n",
    "def inv_hessian():\n",
    "    H = lamb * np.eye(th_D)\n",
    "    if np.sum(np.abs(Slbfgs).sum(1)==0) > 0:\n",
    "        return H\n",
    "    for m in range(1,M):\n",
    "        s = Slbfgs[m,:] - Slbfgs[m-1,:]\n",
    "        y = Ylbfgs[m,:] - Ylbfgs[m-1,:]\n",
    "        t1 = np.eye(th_D) - np.outer(s,y)/np.inner(s,y)\n",
    "        t2 = np.eye(th_D) - np.outer(y,s)/np.inner(s,y)\n",
    "        t3 = np.outer(s,s)/np.inner(y,y)\n",
    "        if np.isnan(t1).sum() + np.isnan(t2).sum() + np.isnan(t3).sum() > 0:\n",
    "            raise ValueError('Hessian contains NaN')\n",
    "        H = np.matmul(np.matmul(t1,H),t2)+t3\n",
    "    return H\n",
    "\n",
    "def hamcmc_new_th(eta=eta,feed_dict=dict_):\n",
    "    H  = inv_hessian()\n",
    "    D  = H.shape[0]\n",
    "    gr = get_grad_vec(feed_dict)\n",
    "    th = get_th_vec()\n",
    "    L  = np.linalg.cholesky(2*eta*H + np.eye(D)*1e-3)\n",
    "    nu = np.matmul(L,np.random.normal(size=D))\n",
    "    new_th_vec = th + eta*np.matmul(H,gr) + nu\n",
    "    th_arr = th_vec_to_arr(new_th_vec) \n",
    "    return th_arr\n",
    "\n",
    "def hamcmc_update_memory(feed_dict=dict_):\n",
    "    gr = get_grad_vec(feed_dict)\n",
    "    th = get_th_vec()\n",
    "    Slbfgs[:-1,:] = Slbfgs[1:,:]\n",
    "    Ylbfgs[:-1,:] = Ylbfgs[1:,:]\n",
    "    Slbfgs[-1,:]  = th\n",
    "    Ylbfgs[-1,:]  = gr\n",
    "\n",
    "propose = hamcmc_new_th # lmc_new_th hamcmc_new_th\n",
    "\n",
    "posts,samples = init_sample_batches(Nsamp)\n",
    "old_post = get_post(dict_)\n",
    "old_th = get_th()\n",
    "save_samples(0,old_post,old_th)\n",
    "\n",
    "for epoch in range(1,Nsamp):\n",
    "    new_th = propose(feed_dict=dict_)\n",
    "    new_post = get_new_post(new_th,dict_)\n",
    "    u = np.random.rand()\n",
    "    if np.log(u) < new_post-old_post:\n",
    "        set_th(new_th)\n",
    "        hamcmc_update_memory(dict_)\n",
    "        old_post = new_post\n",
    "        old_th = new_th\n",
    "        action = 'accept'\n",
    "    else:\n",
    "        action = 'reject'\n",
    "    save_samples(epoch,old_post,old_th)\n",
    "    print('{:<8d}'.format(epoch)+'{:<8s}'.format(action)+'{:<16.3f}'.format(old_post))\n",
    "    \n",
    "print('completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot sampled trajectories\n",
    "\n",
    "t  = npde.dataset.t\n",
    "Y  = npde.dataset.Y\n",
    "Z = npde.Z.eval()\n",
    "ts = np.linspace(0,7,100)\n",
    "\n",
    "true_cycle = em_int(ftrue,lambda x,t:0,Y[0][0,:],ts)\n",
    "\n",
    "ts = ts.reshape((1,-1))\n",
    "t_ = tf.constant(ts,dtype=tf.float32)\n",
    "x0_ = tf.constant([[2.,-2.]],dtype=tf.float32)\n",
    "lens_ = tf.constant([np.size(ts)],dtype=tf.int32)\n",
    "\n",
    "smp_idx = range(10,samples[0].shape[0],10) # thinning\n",
    "\n",
    "Xp = []\n",
    "Us = []\n",
    "for i in smp_idx:\n",
    "    tf.assign(npde.U,samples[0][i]).eval()\n",
    "    Xp_i = npde.integrator.forward(t_,x0_,lens_).eval()\n",
    "    Xp.append(np.squeeze(Xp_i))\n",
    "    Us.append(samples[0][i])\n",
    "    \n",
    "plt.figure(1,figsize=(15,10))\n",
    "gs = GridSpec(4, 2)\n",
    "ax1 = plt.subplot(gs[0:4,0])\n",
    "for i in range(len(Xp)):\n",
    "    ax1.plot(Xp[i][:,0],Xp[i][:,1],'-k',alpha=0.5)\n",
    "ax1.scatter(Z[:,0],Z[:,1],40, facecolors='none', edgecolors='k')\n",
    "for i in range(len(Xp)):\n",
    "    ax1.quiver(Z[:,0],Z[:,1],Us[i][:,0],Us[i][:,1],units='height',\\\n",
    "               width=0.003,color='k',alpha=0.5)\n",
    "ax1.plot(true_cycle[:,0],true_cycle[:,1],'-r',linewidth=3,label='true')\n",
    "pathh, = ax1.plot(Y[0][:,0],Y[0][:,1],'o',color='#33FF00',markersize=4)\n",
    "handles_=[pathh]\n",
    "ax1.set_xlabel('$x_1$', fontsize=12)\n",
    "ax1.set_ylabel('$x_2$', fontsize=12)\n",
    "ax1.legend(handles=handles_,loc=1)\n",
    "for d in range(2):\n",
    "    ax = plt.subplot(gs[d,1])\n",
    "    for i in range(len(Xp)):\n",
    "        ax.plot(ts[0],Xp[i][:,d],'-k',alpha=0.5)\n",
    "    pathh, = ax.plot(t[0],Y[0][:,d],'o',color='#33FF00',markersize=2,label='data')\n",
    "    handles_=[pathh]\n",
    "    ax.set_xlabel('$t$', fontsize=12)\n",
    "    trueh, = ax.plot(ts[0],true_cycle[:,d],'-r',linewidth=2,label='true')\n",
    "    handles_.append(trueh)\n",
    "    ax.set_ylabel('$x_{:d}$'.format(d+1), fontsize=12)\n",
    "    if d==0:\n",
    "        ax.legend(handles=handles_,loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HMC or MALA\n",
    "# there seems to be a tiny bug below\n",
    "from tensorflow_probability.python.mcmc.util import maybe_call_fn_and_grads\n",
    "\n",
    "initial_state = (npde.sn,npde.U)\n",
    "log_prob_0, grad_0 = maybe_call_fn_and_grads(npde_post,initial_state)\n",
    "\n",
    "# sampled variables are explicitly set below\n",
    "print(tf.trainable_variables())\n",
    "method = 'hmc' # 'hmc' 'mala'\n",
    "\n",
    "if npde.name == 'npode':\n",
    "    initial_state = (npde.sn,npde.U)\n",
    "else:\n",
    "    initial_state = (npde.sn,npde.U,npde.diffus.kern_time.sf,npde.diffus.kern_time.ell)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "num_results = int(5e2)\n",
    "num_burnin_steps = int(1)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if method == 'hmc':\n",
    "    num_leapfrog_steps = 5\n",
    "    step_size = 0.001\n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                    target_log_prob_fn = npde_post,\n",
    "                    step_size = step_size,\n",
    "                    num_leapfrog_steps = num_leapfrog_steps)\n",
    "elif method == 'mala':\n",
    "    step_size = 0.0001\n",
    "    kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(\n",
    "        target_log_prob_fn=npde_post, step_size=step_size)\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(\n",
    "        num_results = num_results,\n",
    "        num_burnin_steps = num_burnin_steps,\n",
    "        current_state = initial_state, \n",
    "        kernel = kernel)\n",
    "samples_ = samples\n",
    "\n",
    "samples = [sess.run(op) for op in samples]\n",
    "Us = samples[1]\n",
    "time2 = time.time()\n",
    "print(time2-time1)\n",
    "\n",
    "lp = sess.run(kernel_results.accepted_results.target_log_prob)\n",
    "\n",
    "time2 = time.time()\n",
    "print(time2-time1)\n",
    "print(len(np.unique(lp)))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
